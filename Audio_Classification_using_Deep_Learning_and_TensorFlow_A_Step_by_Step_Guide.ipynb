{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Melo567/3d/blob/main/Audio_Classification_using_Deep_Learning_and_TensorFlow_A_Step_by_Step_Guide.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.image import resize\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Step 1: Define your folder structure\n",
        "data_dir = 'drive/MyDrive/dunstan'\n",
        "classes = ['alone', 'brup', 'colic', 'discomfort','hungry', 'pond', 'sleep', 'thirsty','tooth']\n",
        "\n",
        "# Step 2: Load and preprocess audio data\n",
        "def load_and_preprocess_data(data_dir, classes, target_shape=(128, 128)):\n",
        "    data = []\n",
        "    labels = []\n",
        "\n",
        "    for i, class_name in enumerate(classes):\n",
        "        class_dir = os.path.join(data_dir, class_name)\n",
        "        for filename in os.listdir(class_dir):\n",
        "            if filename.endswith('.wav'):\n",
        "                file_path = os.path.join(class_dir, filename)\n",
        "                audio_data, sample_rate = librosa.load(file_path, sr=None)\n",
        "                # Perform preprocessing (e.g., convert to Mel spectrogram and resize)\n",
        "                mel_spectrogram = librosa.feature.melspectrogram(y=audio_data, sr=sample_rate)\n",
        "                mel_spectrogram = resize(np.expand_dims(mel_spectrogram, axis=-1), target_shape)\n",
        "                data.append(mel_spectrogram)\n",
        "                labels.append(i)\n",
        "\n",
        "    return np.array(data), np.array(labels)\n",
        "\n",
        "# Step 3: Split data into training and testing sets\n",
        "data, labels = load_and_preprocess_data(data_dir, classes)\n",
        "labels = to_categorical(labels, num_classes=len(classes))  # Convert labels to one-hot encoding\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 4: Create a neural network model\n",
        "input_shape = X_train[0].shape\n",
        "input_layer = Input(shape=input_shape)\n",
        "x = Conv2D(32, (3, 3), activation='relu')(input_layer)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "x = Conv2D(64, (3, 3), activation='relu')(x)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(64, activation='relu')(x)\n",
        "output_layer = Dense(len(classes), activation='softmax')(x)\n",
        "model = Model(input_layer, output_layer)\n",
        "\n",
        "# Step 5: Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Step 6: Train the model\n",
        "model.fit(X_train, y_train, epochs=200, batch_size=32, validation_data=(X_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sOmhALO0LlY9",
        "outputId": "6267dfb3-70fc-4bd4-bfc4-291b1e801e58"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 481ms/step - accuracy: 0.1417 - loss: 3.8163 - val_accuracy: 0.2727 - val_loss: 24.5221\n",
            "Epoch 2/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 235ms/step - accuracy: 0.6292 - loss: 2.3123 - val_accuracy: 0.1818 - val_loss: 22.8129\n",
            "Epoch 3/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 433ms/step - accuracy: 0.9229 - loss: 0.3966 - val_accuracy: 0.2727 - val_loss: 20.6597\n",
            "Epoch 4/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 463ms/step - accuracy: 0.9187 - loss: 0.3616 - val_accuracy: 0.1818 - val_loss: 18.4231\n",
            "Epoch 5/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 253ms/step - accuracy: 0.8917 - loss: 0.3272 - val_accuracy: 0.1818 - val_loss: 17.7888\n",
            "Epoch 6/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 237ms/step - accuracy: 0.9187 - loss: 0.2953 - val_accuracy: 0.1818 - val_loss: 18.4859\n",
            "Epoch 7/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 257ms/step - accuracy: 0.9563 - loss: 0.2238 - val_accuracy: 0.1818 - val_loss: 19.7542\n",
            "Epoch 8/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 237ms/step - accuracy: 0.9563 - loss: 0.1776 - val_accuracy: 0.1818 - val_loss: 21.7807\n",
            "Epoch 9/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 241ms/step - accuracy: 0.9667 - loss: 0.1136 - val_accuracy: 0.2727 - val_loss: 24.7986\n",
            "Epoch 10/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 236ms/step - accuracy: 0.9729 - loss: 0.0907 - val_accuracy: 0.1818 - val_loss: 30.8792\n",
            "Epoch 11/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 239ms/step - accuracy: 1.0000 - loss: 0.0782 - val_accuracy: 0.1818 - val_loss: 39.0126\n",
            "Epoch 12/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 257ms/step - accuracy: 1.0000 - loss: 0.0526 - val_accuracy: 0.1818 - val_loss: 47.6613\n",
            "Epoch 13/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 291ms/step - accuracy: 1.0000 - loss: 0.0324 - val_accuracy: 0.1818 - val_loss: 57.1389\n",
            "Epoch 14/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 411ms/step - accuracy: 1.0000 - loss: 0.0229 - val_accuracy: 0.1818 - val_loss: 65.8992\n",
            "Epoch 15/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 415ms/step - accuracy: 1.0000 - loss: 0.0163 - val_accuracy: 0.1818 - val_loss: 72.5056\n",
            "Epoch 16/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 473ms/step - accuracy: 1.0000 - loss: 0.0099 - val_accuracy: 0.1818 - val_loss: 74.3544\n",
            "Epoch 17/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 243ms/step - accuracy: 1.0000 - loss: 0.0057 - val_accuracy: 0.0909 - val_loss: 73.1173\n",
            "Epoch 18/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 242ms/step - accuracy: 1.0000 - loss: 0.0037 - val_accuracy: 0.0909 - val_loss: 72.3748\n",
            "Epoch 19/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 248ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 0.0909 - val_loss: 72.3008\n",
            "Epoch 20/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 256ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.0909 - val_loss: 72.5141\n",
            "Epoch 21/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 263ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.0909 - val_loss: 72.8242\n",
            "Epoch 22/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 466ms/step - accuracy: 1.0000 - loss: 7.0905e-04 - val_accuracy: 0.0909 - val_loss: 73.1383\n",
            "Epoch 23/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 493ms/step - accuracy: 1.0000 - loss: 3.8565e-04 - val_accuracy: 0.0909 - val_loss: 73.4721\n",
            "Epoch 24/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 408ms/step - accuracy: 1.0000 - loss: 4.3883e-04 - val_accuracy: 0.0909 - val_loss: 73.9650\n",
            "Epoch 25/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 467ms/step - accuracy: 1.0000 - loss: 3.4273e-04 - val_accuracy: 0.0909 - val_loss: 74.4405\n",
            "Epoch 26/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 406ms/step - accuracy: 1.0000 - loss: 2.6614e-04 - val_accuracy: 0.0909 - val_loss: 74.9008\n",
            "Epoch 27/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 243ms/step - accuracy: 1.0000 - loss: 1.9805e-04 - val_accuracy: 0.0909 - val_loss: 75.2681\n",
            "Epoch 28/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 238ms/step - accuracy: 1.0000 - loss: 1.8649e-04 - val_accuracy: 0.0909 - val_loss: 75.4882\n",
            "Epoch 29/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 250ms/step - accuracy: 1.0000 - loss: 1.5945e-04 - val_accuracy: 0.0909 - val_loss: 75.6462\n",
            "Epoch 30/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 241ms/step - accuracy: 1.0000 - loss: 1.3910e-04 - val_accuracy: 0.0909 - val_loss: 75.7578\n",
            "Epoch 31/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 239ms/step - accuracy: 1.0000 - loss: 9.4990e-05 - val_accuracy: 0.0909 - val_loss: 75.8519\n",
            "Epoch 32/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 253ms/step - accuracy: 1.0000 - loss: 1.1450e-04 - val_accuracy: 0.0909 - val_loss: 75.9629\n",
            "Epoch 33/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 257ms/step - accuracy: 1.0000 - loss: 9.5570e-05 - val_accuracy: 0.0909 - val_loss: 76.0465\n",
            "Epoch 34/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 236ms/step - accuracy: 1.0000 - loss: 9.3299e-05 - val_accuracy: 0.0909 - val_loss: 76.0865\n",
            "Epoch 35/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 367ms/step - accuracy: 1.0000 - loss: 9.0594e-05 - val_accuracy: 0.0909 - val_loss: 76.1219\n",
            "Epoch 36/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 386ms/step - accuracy: 1.0000 - loss: 8.4660e-05 - val_accuracy: 0.0909 - val_loss: 76.1571\n",
            "Epoch 37/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 381ms/step - accuracy: 1.0000 - loss: 7.9962e-05 - val_accuracy: 0.0909 - val_loss: 76.1955\n",
            "Epoch 38/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 235ms/step - accuracy: 1.0000 - loss: 7.3343e-05 - val_accuracy: 0.0909 - val_loss: 76.2390\n",
            "Epoch 39/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 241ms/step - accuracy: 1.0000 - loss: 7.2686e-05 - val_accuracy: 0.0909 - val_loss: 76.2854\n",
            "Epoch 40/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 248ms/step - accuracy: 1.0000 - loss: 6.3161e-05 - val_accuracy: 0.0909 - val_loss: 76.3340\n",
            "Epoch 41/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 262ms/step - accuracy: 1.0000 - loss: 6.8203e-05 - val_accuracy: 0.0909 - val_loss: 76.3792\n",
            "Epoch 42/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 238ms/step - accuracy: 1.0000 - loss: 4.8183e-05 - val_accuracy: 0.0909 - val_loss: 76.4453\n",
            "Epoch 43/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 241ms/step - accuracy: 1.0000 - loss: 5.6920e-05 - val_accuracy: 0.0909 - val_loss: 76.5308\n",
            "Epoch 44/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 272ms/step - accuracy: 1.0000 - loss: 6.1495e-05 - val_accuracy: 0.0909 - val_loss: 76.6024\n",
            "Epoch 45/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 269ms/step - accuracy: 1.0000 - loss: 5.9238e-05 - val_accuracy: 0.0909 - val_loss: 76.6798\n",
            "Epoch 46/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 343ms/step - accuracy: 1.0000 - loss: 5.3396e-05 - val_accuracy: 0.0909 - val_loss: 76.7535\n",
            "Epoch 47/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 410ms/step - accuracy: 1.0000 - loss: 3.9629e-05 - val_accuracy: 0.0909 - val_loss: 76.8338\n",
            "Epoch 48/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 455ms/step - accuracy: 1.0000 - loss: 5.2823e-05 - val_accuracy: 0.0909 - val_loss: 76.9393\n",
            "Epoch 49/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 245ms/step - accuracy: 1.0000 - loss: 5.3040e-05 - val_accuracy: 0.0909 - val_loss: 77.0411\n",
            "Epoch 50/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 252ms/step - accuracy: 1.0000 - loss: 5.0804e-05 - val_accuracy: 0.0909 - val_loss: 77.1387\n",
            "Epoch 51/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 242ms/step - accuracy: 1.0000 - loss: 4.4326e-05 - val_accuracy: 0.0909 - val_loss: 77.2333\n",
            "Epoch 52/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 238ms/step - accuracy: 1.0000 - loss: 3.1945e-05 - val_accuracy: 0.0909 - val_loss: 77.3335\n",
            "Epoch 53/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 240ms/step - accuracy: 1.0000 - loss: 4.3694e-05 - val_accuracy: 0.0909 - val_loss: 77.4362\n",
            "Epoch 54/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 246ms/step - accuracy: 1.0000 - loss: 4.5984e-05 - val_accuracy: 0.0909 - val_loss: 77.5215\n",
            "Epoch 55/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 233ms/step - accuracy: 1.0000 - loss: 3.5063e-05 - val_accuracy: 0.0909 - val_loss: 77.6140\n",
            "Epoch 56/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 232ms/step - accuracy: 1.0000 - loss: 4.3890e-05 - val_accuracy: 0.0909 - val_loss: 77.7243\n",
            "Epoch 57/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 254ms/step - accuracy: 1.0000 - loss: 3.7545e-05 - val_accuracy: 0.0909 - val_loss: 77.8210\n",
            "Epoch 58/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 358ms/step - accuracy: 1.0000 - loss: 3.6863e-05 - val_accuracy: 0.0909 - val_loss: 77.8963\n",
            "Epoch 59/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 411ms/step - accuracy: 1.0000 - loss: 4.1046e-05 - val_accuracy: 0.0909 - val_loss: 77.9619\n",
            "Epoch 60/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 436ms/step - accuracy: 1.0000 - loss: 3.7135e-05 - val_accuracy: 0.0909 - val_loss: 78.0263\n",
            "Epoch 61/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 395ms/step - accuracy: 1.0000 - loss: 3.9292e-05 - val_accuracy: 0.0909 - val_loss: 78.0863\n",
            "Epoch 62/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 241ms/step - accuracy: 1.0000 - loss: 3.6828e-05 - val_accuracy: 0.0909 - val_loss: 78.1429\n",
            "Epoch 63/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 255ms/step - accuracy: 1.0000 - loss: 3.7939e-05 - val_accuracy: 0.0909 - val_loss: 78.2023\n",
            "Epoch 64/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 239ms/step - accuracy: 1.0000 - loss: 3.7416e-05 - val_accuracy: 0.0909 - val_loss: 78.2671\n",
            "Epoch 65/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 245ms/step - accuracy: 1.0000 - loss: 3.5189e-05 - val_accuracy: 0.0909 - val_loss: 78.3316\n",
            "Epoch 66/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 258ms/step - accuracy: 1.0000 - loss: 3.5107e-05 - val_accuracy: 0.0909 - val_loss: 78.3979\n",
            "Epoch 67/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 238ms/step - accuracy: 1.0000 - loss: 3.5586e-05 - val_accuracy: 0.0909 - val_loss: 78.4722\n",
            "Epoch 68/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 236ms/step - accuracy: 1.0000 - loss: 3.3928e-05 - val_accuracy: 0.0909 - val_loss: 78.5431\n",
            "Epoch 69/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 237ms/step - accuracy: 1.0000 - loss: 3.4694e-05 - val_accuracy: 0.0909 - val_loss: 78.6108\n",
            "Epoch 70/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 245ms/step - accuracy: 1.0000 - loss: 3.4478e-05 - val_accuracy: 0.0909 - val_loss: 78.6767\n",
            "Epoch 71/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 246ms/step - accuracy: 1.0000 - loss: 3.1775e-05 - val_accuracy: 0.0909 - val_loss: 78.7302\n",
            "Epoch 72/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 384ms/step - accuracy: 1.0000 - loss: 3.1292e-05 - val_accuracy: 0.0909 - val_loss: 78.7618\n",
            "Epoch 73/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 378ms/step - accuracy: 1.0000 - loss: 3.2922e-05 - val_accuracy: 0.0909 - val_loss: 78.7884\n",
            "Epoch 74/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 241ms/step - accuracy: 1.0000 - loss: 3.2447e-05 - val_accuracy: 0.0909 - val_loss: 78.8225\n",
            "Epoch 75/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 240ms/step - accuracy: 1.0000 - loss: 2.9987e-05 - val_accuracy: 0.0909 - val_loss: 78.8585\n",
            "Epoch 76/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 236ms/step - accuracy: 1.0000 - loss: 2.4779e-05 - val_accuracy: 0.0909 - val_loss: 78.9105\n",
            "Epoch 77/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 241ms/step - accuracy: 1.0000 - loss: 3.1276e-05 - val_accuracy: 0.0909 - val_loss: 78.9845\n",
            "Epoch 78/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 259ms/step - accuracy: 1.0000 - loss: 2.2045e-05 - val_accuracy: 0.0909 - val_loss: 79.0655\n",
            "Epoch 79/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 268ms/step - accuracy: 1.0000 - loss: 2.3762e-05 - val_accuracy: 0.0909 - val_loss: 79.1796\n",
            "Epoch 80/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 235ms/step - accuracy: 1.0000 - loss: 2.9840e-05 - val_accuracy: 0.0909 - val_loss: 79.3109\n",
            "Epoch 81/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 250ms/step - accuracy: 1.0000 - loss: 2.8246e-05 - val_accuracy: 0.0909 - val_loss: 79.4299\n",
            "Epoch 82/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 361ms/step - accuracy: 1.0000 - loss: 2.6746e-05 - val_accuracy: 0.0909 - val_loss: 79.5325\n",
            "Epoch 83/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 466ms/step - accuracy: 1.0000 - loss: 2.8394e-05 - val_accuracy: 0.0909 - val_loss: 79.6209\n",
            "Epoch 84/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 455ms/step - accuracy: 1.0000 - loss: 2.1931e-05 - val_accuracy: 0.0909 - val_loss: 79.7101\n",
            "Epoch 85/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 254ms/step - accuracy: 1.0000 - loss: 2.7680e-05 - val_accuracy: 0.0909 - val_loss: 79.8033\n",
            "Epoch 86/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 236ms/step - accuracy: 1.0000 - loss: 2.1360e-05 - val_accuracy: 0.0909 - val_loss: 79.8944\n",
            "Epoch 87/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 231ms/step - accuracy: 1.0000 - loss: 2.0068e-05 - val_accuracy: 0.0909 - val_loss: 80.0049\n",
            "Epoch 88/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 260ms/step - accuracy: 1.0000 - loss: 2.6236e-05 - val_accuracy: 0.0909 - val_loss: 80.1222\n",
            "Epoch 89/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 269ms/step - accuracy: 1.0000 - loss: 2.4577e-05 - val_accuracy: 0.0909 - val_loss: 80.2156\n",
            "Epoch 90/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 243ms/step - accuracy: 1.0000 - loss: 2.4179e-05 - val_accuracy: 0.0909 - val_loss: 80.2894\n",
            "Epoch 91/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 244ms/step - accuracy: 1.0000 - loss: 2.3809e-05 - val_accuracy: 0.0909 - val_loss: 80.3472\n",
            "Epoch 92/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 251ms/step - accuracy: 1.0000 - loss: 2.4819e-05 - val_accuracy: 0.0909 - val_loss: 80.3958\n",
            "Epoch 93/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 335ms/step - accuracy: 1.0000 - loss: 2.0472e-05 - val_accuracy: 0.0909 - val_loss: 80.4343\n",
            "Epoch 94/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 475ms/step - accuracy: 1.0000 - loss: 2.2828e-05 - val_accuracy: 0.1818 - val_loss: 80.4618\n",
            "Epoch 95/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 256ms/step - accuracy: 1.0000 - loss: 2.3640e-05 - val_accuracy: 0.1818 - val_loss: 80.4930\n",
            "Epoch 96/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 237ms/step - accuracy: 1.0000 - loss: 1.7353e-05 - val_accuracy: 0.1818 - val_loss: 80.5429\n",
            "Epoch 97/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 242ms/step - accuracy: 1.0000 - loss: 1.7191e-05 - val_accuracy: 0.1818 - val_loss: 80.6296\n",
            "Epoch 98/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 271ms/step - accuracy: 1.0000 - loss: 2.1988e-05 - val_accuracy: 0.1818 - val_loss: 80.7341\n",
            "Epoch 99/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 239ms/step - accuracy: 1.0000 - loss: 2.0612e-05 - val_accuracy: 0.1818 - val_loss: 80.8361\n",
            "Epoch 100/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 240ms/step - accuracy: 1.0000 - loss: 2.2120e-05 - val_accuracy: 0.1818 - val_loss: 80.9300\n",
            "Epoch 101/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 245ms/step - accuracy: 1.0000 - loss: 1.7316e-05 - val_accuracy: 0.1818 - val_loss: 81.0230\n",
            "Epoch 102/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 236ms/step - accuracy: 1.0000 - loss: 1.8808e-05 - val_accuracy: 0.1818 - val_loss: 81.1177\n",
            "Epoch 103/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 238ms/step - accuracy: 1.0000 - loss: 2.0422e-05 - val_accuracy: 0.1818 - val_loss: 81.1982\n",
            "Epoch 104/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 308ms/step - accuracy: 1.0000 - loss: 2.0817e-05 - val_accuracy: 0.1818 - val_loss: 81.2702\n",
            "Epoch 105/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 396ms/step - accuracy: 1.0000 - loss: 1.6369e-05 - val_accuracy: 0.1818 - val_loss: 81.3373\n",
            "Epoch 106/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 486ms/step - accuracy: 1.0000 - loss: 1.9651e-05 - val_accuracy: 0.1818 - val_loss: 81.4078\n",
            "Epoch 107/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 388ms/step - accuracy: 1.0000 - loss: 1.9030e-05 - val_accuracy: 0.1818 - val_loss: 81.4692\n",
            "Epoch 108/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 238ms/step - accuracy: 1.0000 - loss: 1.5198e-05 - val_accuracy: 0.1818 - val_loss: 81.5274\n",
            "Epoch 109/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 239ms/step - accuracy: 1.0000 - loss: 1.5540e-05 - val_accuracy: 0.1818 - val_loss: 81.6075\n",
            "Epoch 110/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 344ms/step - accuracy: 1.0000 - loss: 1.3297e-05 - val_accuracy: 0.1818 - val_loss: 81.6967\n",
            "Epoch 111/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 510ms/step - accuracy: 1.0000 - loss: 1.8920e-05 - val_accuracy: 0.1818 - val_loss: 81.7800\n",
            "Epoch 112/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 417ms/step - accuracy: 1.0000 - loss: 1.8561e-05 - val_accuracy: 0.1818 - val_loss: 81.8496\n",
            "Epoch 113/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 365ms/step - accuracy: 1.0000 - loss: 1.4733e-05 - val_accuracy: 0.1818 - val_loss: 81.9157\n",
            "Epoch 114/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 409ms/step - accuracy: 1.0000 - loss: 1.7468e-05 - val_accuracy: 0.1818 - val_loss: 81.9882\n",
            "Epoch 115/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 448ms/step - accuracy: 1.0000 - loss: 1.7626e-05 - val_accuracy: 0.1818 - val_loss: 82.0575\n",
            "Epoch 116/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 421ms/step - accuracy: 1.0000 - loss: 1.7154e-05 - val_accuracy: 0.1818 - val_loss: 82.1222\n",
            "Epoch 117/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 236ms/step - accuracy: 1.0000 - loss: 1.7457e-05 - val_accuracy: 0.1818 - val_loss: 82.1851\n",
            "Epoch 118/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 247ms/step - accuracy: 1.0000 - loss: 1.6532e-05 - val_accuracy: 0.1818 - val_loss: 82.2448\n",
            "Epoch 119/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 268ms/step - accuracy: 1.0000 - loss: 1.7029e-05 - val_accuracy: 0.1818 - val_loss: 82.3034\n",
            "Epoch 120/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 257ms/step - accuracy: 1.0000 - loss: 1.6938e-05 - val_accuracy: 0.1818 - val_loss: 82.3559\n",
            "Epoch 121/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 261ms/step - accuracy: 1.0000 - loss: 1.4832e-05 - val_accuracy: 0.1818 - val_loss: 82.3949\n",
            "Epoch 122/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 242ms/step - accuracy: 1.0000 - loss: 1.6576e-05 - val_accuracy: 0.1818 - val_loss: 82.4237\n",
            "Epoch 123/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 235ms/step - accuracy: 1.0000 - loss: 1.6442e-05 - val_accuracy: 0.1818 - val_loss: 82.4513\n",
            "Epoch 124/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 242ms/step - accuracy: 1.0000 - loss: 1.3162e-05 - val_accuracy: 0.1818 - val_loss: 82.4851\n",
            "Epoch 125/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 246ms/step - accuracy: 1.0000 - loss: 1.5512e-05 - val_accuracy: 0.1818 - val_loss: 82.5308\n",
            "Epoch 126/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 238ms/step - accuracy: 1.0000 - loss: 1.4617e-05 - val_accuracy: 0.1818 - val_loss: 82.5746\n",
            "Epoch 127/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 385ms/step - accuracy: 1.0000 - loss: 1.2908e-05 - val_accuracy: 0.1818 - val_loss: 82.6218\n",
            "Epoch 128/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 414ms/step - accuracy: 1.0000 - loss: 1.4613e-05 - val_accuracy: 0.1818 - val_loss: 82.6767\n",
            "Epoch 129/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 475ms/step - accuracy: 1.0000 - loss: 1.5372e-05 - val_accuracy: 0.1818 - val_loss: 82.7191\n",
            "Epoch 130/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 256ms/step - accuracy: 1.0000 - loss: 1.1593e-05 - val_accuracy: 0.1818 - val_loss: 82.7610\n",
            "Epoch 131/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 240ms/step - accuracy: 1.0000 - loss: 1.4277e-05 - val_accuracy: 0.1818 - val_loss: 82.8061\n",
            "Epoch 132/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 255ms/step - accuracy: 1.0000 - loss: 1.4850e-05 - val_accuracy: 0.1818 - val_loss: 82.8419\n",
            "Epoch 133/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 250ms/step - accuracy: 1.0000 - loss: 1.4595e-05 - val_accuracy: 0.1818 - val_loss: 82.8746\n",
            "Epoch 134/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 243ms/step - accuracy: 1.0000 - loss: 1.4471e-05 - val_accuracy: 0.1818 - val_loss: 82.9101\n",
            "Epoch 135/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 243ms/step - accuracy: 1.0000 - loss: 1.3304e-05 - val_accuracy: 0.1818 - val_loss: 82.9434\n",
            "Epoch 136/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 255ms/step - accuracy: 1.0000 - loss: 1.3879e-05 - val_accuracy: 0.1818 - val_loss: 82.9747\n",
            "Epoch 137/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 254ms/step - accuracy: 1.0000 - loss: 9.9622e-06 - val_accuracy: 0.1818 - val_loss: 83.0191\n",
            "Epoch 138/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 244ms/step - accuracy: 1.0000 - loss: 1.4016e-05 - val_accuracy: 0.1818 - val_loss: 83.0775\n",
            "Epoch 139/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 250ms/step - accuracy: 1.0000 - loss: 1.3401e-05 - val_accuracy: 0.1818 - val_loss: 83.1295\n",
            "Epoch 140/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 249ms/step - accuracy: 1.0000 - loss: 1.3628e-05 - val_accuracy: 0.1818 - val_loss: 83.1737\n",
            "Epoch 141/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 371ms/step - accuracy: 1.0000 - loss: 1.3679e-05 - val_accuracy: 0.1818 - val_loss: 83.2095\n",
            "Epoch 142/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 480ms/step - accuracy: 1.0000 - loss: 1.3574e-05 - val_accuracy: 0.1818 - val_loss: 83.2413\n",
            "Epoch 143/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 448ms/step - accuracy: 1.0000 - loss: 1.0159e-05 - val_accuracy: 0.1818 - val_loss: 83.2742\n",
            "Epoch 144/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 245ms/step - accuracy: 1.0000 - loss: 1.2131e-05 - val_accuracy: 0.1818 - val_loss: 83.3131\n",
            "Epoch 145/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 258ms/step - accuracy: 1.0000 - loss: 1.0585e-05 - val_accuracy: 0.1818 - val_loss: 83.3586\n",
            "Epoch 146/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 240ms/step - accuracy: 1.0000 - loss: 1.1197e-05 - val_accuracy: 0.1818 - val_loss: 83.4079\n",
            "Epoch 147/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 244ms/step - accuracy: 1.0000 - loss: 1.2064e-05 - val_accuracy: 0.1818 - val_loss: 83.4408\n",
            "Epoch 148/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 257ms/step - accuracy: 1.0000 - loss: 1.2750e-05 - val_accuracy: 0.1818 - val_loss: 83.4719\n",
            "Epoch 149/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 246ms/step - accuracy: 1.0000 - loss: 1.1520e-05 - val_accuracy: 0.1818 - val_loss: 83.5051\n",
            "Epoch 150/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 236ms/step - accuracy: 1.0000 - loss: 1.2062e-05 - val_accuracy: 0.1818 - val_loss: 83.5440\n",
            "Epoch 151/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 244ms/step - accuracy: 1.0000 - loss: 8.6416e-06 - val_accuracy: 0.1818 - val_loss: 83.5987\n",
            "Epoch 152/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 253ms/step - accuracy: 1.0000 - loss: 1.1563e-05 - val_accuracy: 0.1818 - val_loss: 83.6659\n",
            "Epoch 153/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 260ms/step - accuracy: 1.0000 - loss: 1.2018e-05 - val_accuracy: 0.1818 - val_loss: 83.7253\n",
            "Epoch 154/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 485ms/step - accuracy: 1.0000 - loss: 1.0781e-05 - val_accuracy: 0.1818 - val_loss: 83.7819\n",
            "Epoch 155/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 428ms/step - accuracy: 1.0000 - loss: 1.1136e-05 - val_accuracy: 0.1818 - val_loss: 83.8332\n",
            "Epoch 156/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 244ms/step - accuracy: 1.0000 - loss: 9.5307e-06 - val_accuracy: 0.1818 - val_loss: 83.8828\n",
            "Epoch 157/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 248ms/step - accuracy: 1.0000 - loss: 1.1624e-05 - val_accuracy: 0.1818 - val_loss: 83.9391\n",
            "Epoch 158/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 240ms/step - accuracy: 1.0000 - loss: 1.0429e-05 - val_accuracy: 0.1818 - val_loss: 83.9885\n",
            "Epoch 159/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 240ms/step - accuracy: 1.0000 - loss: 9.1716e-06 - val_accuracy: 0.1818 - val_loss: 84.0412\n",
            "Epoch 160/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 252ms/step - accuracy: 1.0000 - loss: 1.0705e-05 - val_accuracy: 0.1818 - val_loss: 84.0998\n",
            "Epoch 161/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 252ms/step - accuracy: 1.0000 - loss: 1.1134e-05 - val_accuracy: 0.1818 - val_loss: 84.1491\n",
            "Epoch 162/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 243ms/step - accuracy: 1.0000 - loss: 1.0146e-05 - val_accuracy: 0.1818 - val_loss: 84.1934\n",
            "Epoch 163/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 240ms/step - accuracy: 1.0000 - loss: 1.0612e-05 - val_accuracy: 0.1818 - val_loss: 84.2355\n",
            "Epoch 164/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 239ms/step - accuracy: 1.0000 - loss: 1.0480e-05 - val_accuracy: 0.1818 - val_loss: 84.2798\n",
            "Epoch 165/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 472ms/step - accuracy: 1.0000 - loss: 9.9104e-06 - val_accuracy: 0.1818 - val_loss: 84.3257\n",
            "Epoch 166/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 478ms/step - accuracy: 1.0000 - loss: 7.8113e-06 - val_accuracy: 0.1818 - val_loss: 84.3740\n",
            "Epoch 167/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 238ms/step - accuracy: 1.0000 - loss: 1.0216e-05 - val_accuracy: 0.1818 - val_loss: 84.4336\n",
            "Epoch 168/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 241ms/step - accuracy: 1.0000 - loss: 9.3144e-06 - val_accuracy: 0.1818 - val_loss: 84.4858\n",
            "Epoch 169/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 249ms/step - accuracy: 1.0000 - loss: 9.8647e-06 - val_accuracy: 0.1818 - val_loss: 84.5244\n",
            "Epoch 170/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 247ms/step - accuracy: 1.0000 - loss: 9.3914e-06 - val_accuracy: 0.1818 - val_loss: 84.5592\n",
            "Epoch 171/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 238ms/step - accuracy: 1.0000 - loss: 9.6059e-06 - val_accuracy: 0.1818 - val_loss: 84.5919\n",
            "Epoch 172/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 245ms/step - accuracy: 1.0000 - loss: 9.8093e-06 - val_accuracy: 0.1818 - val_loss: 84.6251\n",
            "Epoch 173/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 235ms/step - accuracy: 1.0000 - loss: 8.0047e-06 - val_accuracy: 0.1818 - val_loss: 84.6671\n",
            "Epoch 174/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 241ms/step - accuracy: 1.0000 - loss: 9.9035e-06 - val_accuracy: 0.1818 - val_loss: 84.7178\n",
            "Epoch 175/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 249ms/step - accuracy: 1.0000 - loss: 9.7885e-06 - val_accuracy: 0.1818 - val_loss: 84.7670\n",
            "Epoch 176/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 240ms/step - accuracy: 1.0000 - loss: 7.7562e-06 - val_accuracy: 0.1818 - val_loss: 84.8184\n",
            "Epoch 177/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 417ms/step - accuracy: 1.0000 - loss: 9.6239e-06 - val_accuracy: 0.1818 - val_loss: 84.8750\n",
            "Epoch 178/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 434ms/step - accuracy: 1.0000 - loss: 9.2638e-06 - val_accuracy: 0.1818 - val_loss: 84.9253\n",
            "Epoch 179/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 244ms/step - accuracy: 1.0000 - loss: 9.5509e-06 - val_accuracy: 0.1818 - val_loss: 84.9712\n",
            "Epoch 180/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 266ms/step - accuracy: 1.0000 - loss: 8.7244e-06 - val_accuracy: 0.1818 - val_loss: 85.0060\n",
            "Epoch 181/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 258ms/step - accuracy: 1.0000 - loss: 6.8607e-06 - val_accuracy: 0.1818 - val_loss: 85.0308\n",
            "Epoch 182/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 255ms/step - accuracy: 1.0000 - loss: 8.9782e-06 - val_accuracy: 0.1818 - val_loss: 85.0578\n",
            "Epoch 183/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 303ms/step - accuracy: 1.0000 - loss: 9.2067e-06 - val_accuracy: 0.1818 - val_loss: 85.0855\n",
            "Epoch 184/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 262ms/step - accuracy: 1.0000 - loss: 8.4306e-06 - val_accuracy: 0.1818 - val_loss: 85.1134\n",
            "Epoch 185/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 245ms/step - accuracy: 1.0000 - loss: 6.6180e-06 - val_accuracy: 0.1818 - val_loss: 85.1461\n",
            "Epoch 186/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 250ms/step - accuracy: 1.0000 - loss: 7.0539e-06 - val_accuracy: 0.1818 - val_loss: 85.1969\n",
            "Epoch 187/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 250ms/step - accuracy: 1.0000 - loss: 8.6099e-06 - val_accuracy: 0.1818 - val_loss: 85.2593\n",
            "Epoch 188/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 411ms/step - accuracy: 1.0000 - loss: 8.8049e-06 - val_accuracy: 0.1818 - val_loss: 85.3171\n",
            "Epoch 189/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 436ms/step - accuracy: 1.0000 - loss: 8.6845e-06 - val_accuracy: 0.1818 - val_loss: 85.3665\n",
            "Epoch 190/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 239ms/step - accuracy: 1.0000 - loss: 8.4371e-06 - val_accuracy: 0.1818 - val_loss: 85.4129\n",
            "Epoch 191/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 248ms/step - accuracy: 1.0000 - loss: 8.2869e-06 - val_accuracy: 0.1818 - val_loss: 85.4590\n",
            "Epoch 192/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 259ms/step - accuracy: 1.0000 - loss: 8.5722e-06 - val_accuracy: 0.1818 - val_loss: 85.5030\n",
            "Epoch 193/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 256ms/step - accuracy: 1.0000 - loss: 8.4744e-06 - val_accuracy: 0.1818 - val_loss: 85.5410\n",
            "Epoch 194/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 260ms/step - accuracy: 1.0000 - loss: 7.7867e-06 - val_accuracy: 0.1818 - val_loss: 85.5714\n",
            "Epoch 195/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 265ms/step - accuracy: 1.0000 - loss: 8.3547e-06 - val_accuracy: 0.1818 - val_loss: 85.5921\n",
            "Epoch 196/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 241ms/step - accuracy: 1.0000 - loss: 7.6141e-06 - val_accuracy: 0.1818 - val_loss: 85.6045\n",
            "Epoch 197/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 239ms/step - accuracy: 1.0000 - loss: 8.1910e-06 - val_accuracy: 0.1818 - val_loss: 85.6087\n",
            "Epoch 198/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 331ms/step - accuracy: 1.0000 - loss: 8.2497e-06 - val_accuracy: 0.1818 - val_loss: 85.6164\n",
            "Epoch 199/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 396ms/step - accuracy: 1.0000 - loss: 6.7025e-06 - val_accuracy: 0.1818 - val_loss: 85.6369\n",
            "Epoch 200/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 275ms/step - accuracy: 1.0000 - loss: 6.6536e-06 - val_accuracy: 0.1818 - val_loss: 85.6774\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x78fe6bd55780>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bsfdFd7hZUWR",
        "outputId": "e83dc455-ec57-419b-fe07-30ffd95a8677"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_accuracy=model.evaluate(X_test,y_test,verbose=0)\n",
        "print(test_accuracy[1])\n",
        "\n",
        "# Step 7: Save the model\n",
        "model.save('dunstan_classification_model.keras')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0u052xpDRw9s",
        "outputId": "d5535585-3fc9-4fd5-e674-6cae42d36a12"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.1818181872367859\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the saved model\n",
        "model = load_model('dunstan_classification_model.keras')\n",
        "\n",
        "# Define the target shape for input spectrograms\n",
        "target_shape = (128, 128)\n",
        "\n",
        "# Define your class labels\n",
        "classes = ['alone', 'brup', 'colic', 'discomfort','hungry', 'pond', 'sleep', 'thirsty','tooth']\n",
        "\n",
        "# Function to preprocess and classify an audio file\n",
        "def test_audio(file_path, model):\n",
        "    # Load and preprocess the audio file\n",
        "    audio_data, sample_rate = librosa.load(file_path, sr=None)\n",
        "    mel_spectrogram = librosa.feature.melspectrogram(y=audio_data, sr=sample_rate)\n",
        "    mel_spectrogram = resize(np.expand_dims(mel_spectrogram, axis=-1), target_shape)\n",
        "    mel_spectrogram = tf.reshape(mel_spectrogram, (1,) + target_shape + (1,))\n",
        "\n",
        "    # Make predictions\n",
        "    predictions = model.predict(mel_spectrogram)\n",
        "\n",
        "    # Get the class probabilities\n",
        "    class_probabilities = predictions[0]\n",
        "\n",
        "    # Get the predicted class index\n",
        "    predicted_class_index = np.argmax(class_probabilities)\n",
        "\n",
        "    return class_probabilities, predicted_class_index\n",
        "\n",
        "# Test an audio file\n",
        "test_audio_file = 'sample_data/gas_colic.wav'\n",
        "class_probabilities, predicted_class_index = test_audio(test_audio_file, model)\n",
        "\n",
        "# Display results for all classes\n",
        "for i, class_label in enumerate(classes):\n",
        "    probability = class_probabilities[i]\n",
        "    print(f'Class: {class_label}, Probability: {probability:.4f}')\n",
        "\n",
        "# Calculate and display the predicted class and accuracy\n",
        "predicted_class = classes[predicted_class_index]\n",
        "accuracy = class_probabilities[predicted_class_index]\n",
        "print(f'The audio is classified as: {predicted_class}')\n",
        "print(f'Accuracy: {accuracy:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sf5l3jBRPoR4",
        "outputId": "e55e80ec-23da-49b0-8677-e784b6a9f63f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step\n",
            "Class: alone, Probability: 0.0000\n",
            "Class: brup, Probability: 1.0000\n",
            "Class: colic, Probability: 0.0000\n",
            "Class: discomfort, Probability: 0.0000\n",
            "Class: hungry, Probability: 0.0000\n",
            "Class: pond, Probability: 0.0000\n",
            "Class: sleep, Probability: 0.0000\n",
            "Class: thirsty, Probability: 0.0000\n",
            "Class: tooth, Probability: 0.0000\n",
            "The audio is classified as: brup\n",
            "Accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model('dunstan_classification_model.keras')\n",
        "\n",
        "# Create the TFLite converter, using the loaded model object\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "\n",
        "# Convert the model\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the TFLite model\n",
        "with open('dunstan_classification_model.tflite', 'wb') as f:\n",
        "    f.write(tflite_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uE2l95fLN_Hb",
        "outputId": "a110d031-7bda-4991-ced7-49f0902c3afc"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved artifact at '/tmp/tmpfq4c_x8i'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 128, 128, 1), dtype=tf.float32, name='input_layer')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 9), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  133034125116864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  133034138445856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  133034134152896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  133034134157296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  133034135681008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  133034137380896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  133034137383360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  133034137376848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
          ]
        }
      ]
    }
  ]
}